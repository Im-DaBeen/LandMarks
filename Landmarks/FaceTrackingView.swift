import SwiftUI
import ARKit
import SceneKit

struct FaceTrackingView: UIViewControllerRepresentable {
    func makeUIViewController(context: Context) -> UIViewController {
        let viewController = UIViewController()
        let sceneView = ARSCNView(frame: viewController.view.bounds)
        sceneView.delegate = context.coordinator

        // Face Tracking ì§€ì› ê¸°ê¸°ì¸ì§€ í™•ì¸
        guard ARFaceTrackingConfiguration.isSupported else {
            print("âŒ ì´ ê¸°ê¸°ëŠ” Face Trackingì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            return viewController
        }

        let config = ARFaceTrackingConfiguration()
        config.isLightEstimationEnabled = true
        sceneView.session.run(config, options: [])

        viewController.view.addSubview(sceneView)
        return viewController
    }

    func updateUIViewController(_ uiViewController: UIViewController, context: Context) {}

    func makeCoordinator() -> Coordinator {
        return Coordinator()
    }

    class Coordinator: NSObject, ARSCNViewDelegate {
        func renderer(_ renderer: SCNSceneRenderer, didUpdate node: SCNNode, for anchor: ARAnchor) {
            guard let faceAnchor = anchor as? ARFaceAnchor else { return }
            let blendShapes = faceAnchor.blendShapes

            let smileLeft = blendShapes[.mouthSmileLeft]?.floatValue ?? 0
            let smileRight = blendShapes[.mouthSmileRight]?.floatValue ?? 0
            let jawOpen = blendShapes[.jawOpen]?.floatValue ?? 0
            let browDownLeft = blendShapes[.browDownLeft]?.floatValue ?? 0

            // ê°„ë‹¨í•œ ê°ì • ì¶”ì •
            if smileLeft > 0.5 && smileRight > 0.5 {
                print("ğŸ˜Š ê°ì •: í–‰ë³µí•´ ë³´ì…ë‹ˆë‹¤.")
            } else if jawOpen > 0.6 {
                print("ğŸ˜® ê°ì •: ë†€ëŒ")
            } else if browDownLeft > 0.6 {
                print("ğŸ˜  ê°ì •: í™”ë‚¨")
            } else {
                print("ğŸ˜ ê°ì •: ì¤‘ë¦½")
            }
        }
    }
}
